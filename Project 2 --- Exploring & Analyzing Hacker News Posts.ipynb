{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Our aim is to analyze Hacker News (HN) posts whose titles begin with either `Ask HN` or `Show HN`.\n",
    "- Users submit Ask HN posts to ask the Hacker News community a specific question.\n",
    "- Users submit Show HN posts to show the Hacker News community a project, product, or just generally something interesting\n",
    "\n",
    "We want to know:\n",
    "- Do Ask HN or Show HN receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Given: Data Set\n",
    "- Data from the Hacker News and the dataset's documentation [are found here.](https://www.kaggle.com/hacker-news/hacker-news-posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "## Step 1: Open the dataset\n",
    "\n",
    "We'll open our data set now and make it ready to be used for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global imports\n",
    "from csv import reader\n",
    "import datetime as dt\n",
    "\n",
    "# open Hacker News .csv file\n",
    "csv_file = open('hacker_news.csv')\n",
    "read_csv = reader(csv_file)\n",
    "hn = list(read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "## Step 2: Explore the data\n",
    "Let's print out a few lines of the datasets to see what they look like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12579008',\n",
       "  'You have two days to comment if you want stem cells to be classified as your own',\n",
       "  'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018',\n",
       "  '1',\n",
       "  '0',\n",
       "  'altstar',\n",
       "  '9/26/2016 3:26'],\n",
       " ['12579005',\n",
       "  'SQLAR  the SQLite Archiver',\n",
       "  'https://www.sqlite.org/sqlar/doc/trunk/README.md',\n",
       "  '1',\n",
       "  '0',\n",
       "  'blacksqr',\n",
       "  '9/26/2016 3:24']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print for Janki's sanity\n",
    "hn[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Clean the data\n",
    "Now that we've opened and explored our dataset, we'll need to scrub and clean the data.\n",
    "\n",
    "This process of preparing our data for analysis is called `data cleaning`. Data cleaning is done before the analysis; it includes removing or correcting wrong data, removing duplicate data, and modifying the data to fit the purpose of our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove header row\n",
    "Let's first start by moving the header row to another variable so that our `hn` list only contains information about each HN article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "# separate out the header row\n",
    "headers = hn[0]\n",
    "del hn[0]\n",
    "\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12579008',\n",
       "  'You have two days to comment if you want stem cells to be classified as your own',\n",
       "  'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018',\n",
       "  '1',\n",
       "  '0',\n",
       "  'altstar',\n",
       "  '9/26/2016 3:26'],\n",
       " ['12579005',\n",
       "  'SQLAR  the SQLite Archiver',\n",
       "  'https://www.sqlite.org/sqlar/doc/trunk/README.md',\n",
       "  '1',\n",
       "  '0',\n",
       "  'blacksqr',\n",
       "  '9/26/2016 3:24']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print for Janki's sanity\n",
    "hn[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows with no comments\n",
    "Let's remove rows for articles that have no comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80401\n"
     ]
    }
   ],
   "source": [
    "# separate out articles with and without comments\n",
    "zero_comm_hn=[]\n",
    "comm_hn=[]\n",
    "\n",
    "for row in hn:\n",
    "    comments=int(row[4])\n",
    "    if comments==0:\n",
    "        zero_comm_hn.append(row)\n",
    "    else:\n",
    "        comm_hn.append(row)\n",
    "        \n",
    "hn = comm_hn\n",
    "\n",
    "print(len(hn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse out `Ask HN` and `Show HN` post rows\n",
    "Let's now create three lists to separate out `Ask HN`, `Show HN`, and `Other Posts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6911\n",
      "5059\n",
      "75342\n",
      "[['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53']]\n",
      "[['12577142', 'Show HN: Jumble  Essays on the go #PaulInYourPocket', 'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8', '1', '1', 'ryderj', '9/25/2016 20:06']]\n",
      "[['12578975', 'Saving the Hassle of Shopping', 'https://blog.menswr.com/2016/09/07/whats-new-with-your-style-feed/', '1', '1', 'bdoux', '9/26/2016 3:13']]\n"
     ]
    }
   ],
   "source": [
    "# create lists that contain only \"showHN\",\n",
    "# \"askHN\", and non-show + non-ask posts (\"other\")\n",
    "ask_posts=[]\n",
    "show_posts=[]\n",
    "other_posts=[]\n",
    "\n",
    "for row in hn:\n",
    "    title=row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    if title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "# print for Janki's sanity\n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n",
    "print(ask_posts[:1])\n",
    "print(show_posts[:1])\n",
    "print(other_posts[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Analyze the data\n",
    "### Comments average\n",
    "Let's determine if ask posts or show posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg ask comments: 14\n",
      "avg show comments: 10\n"
     ]
    }
   ],
   "source": [
    "# calculate the average comments in AskHN\n",
    "total_ask_comments=0\n",
    "num_ask_posts=len(ask_posts)\n",
    "\n",
    "for row in ask_posts:\n",
    "    comms=int(row[4])\n",
    "    total_ask_comments+=comms\n",
    "\n",
    "avg_ask_comments = total_ask_comments/num_ask_posts\n",
    "ask_print=\"avg ask comments: \" + format(round(avg_ask_comments))\n",
    "print(ask_print)\n",
    "\n",
    "\n",
    "\n",
    "# calculate the average comments in ShowHN\n",
    "total_show_comments=0\n",
    "num_show_posts=len(show_posts)\n",
    "\n",
    "for row in show_posts:\n",
    "    comms=int(row[4])\n",
    "    total_show_comments+=comms\n",
    "\n",
    "avg_show_comments = total_show_comments/num_show_posts\n",
    "show_print=\"avg show comments: \" + format(round(avg_show_comments))\n",
    "print(show_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like `Ask HN` posts receive more engagement from users than `Show HN`. However, this is almost to be expected because users are usually more willing to answer a question than they are to comment about a regular post.\n",
    "\n",
    "Since ask posts are more likely to receive comments, we'll focus our remaining analysis just on these posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `AskHN` posts by time\n",
    "Now, we want determine if ask posts created at a certain time are more likely to attract comments.\n",
    "\n",
    "Here's the method we'll use:\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments ask posts receive by hour created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'02': 227, '01': 223, '22': 287, '21': 407, '19': 420, '17': 404, '15': 467, '14': 378, '13': 326, '11': 251, '10': 219, '09': 176, '07': 157, '03': 212, '16': 415, '08': 190, '00': 231, '23': 276, '20': 392, '18': 452, '12': 274, '04': 186, '06': 176, '05': 165}\n",
      " \n",
      "{'02': 2996, '01': 2089, '22': 3372, '21': 4500, '19': 3954, '17': 5547, '15': 18525, '14': 4972, '13': 7245, '11': 2797, '10': 3013, '09': 1477, '07': 1585, '03': 2154, '16': 4466, '08': 2362, '00': 2277, '23': 2297, '20': 4462, '18': 4877, '12': 4234, '04': 2360, '06': 1587, '05': 1838}\n"
     ]
    }
   ],
   "source": [
    "# create a list of when posts were created\n",
    "result_list=[]\n",
    "for row in ask_posts:\n",
    "    created=row[6]\n",
    "    num_comms=int(row[4])\n",
    "    result_list.append([created, num_comms])\n",
    "\n",
    "    \n",
    "\n",
    "#create two dicts: (1) posts by hour,\n",
    "# and (2) comments by hour\n",
    "counts_by_hour={}\n",
    "comments_by_hour={}\n",
    "for row in result_list:\n",
    "    hour=row[0]\n",
    "    comms=row[1]\n",
    "    date1=dt.datetime.strptime(hour,\"%m/%d/%Y %H:%M\")\n",
    "    date2=dt.datetime.strftime(date1, \"%H\")\n",
    "    if date2 not in counts_by_hour:\n",
    "        counts_by_hour[date2]=1\n",
    "        comments_by_hour[date2]=comms\n",
    "    else:\n",
    "        counts_by_hour[date2]+=1\n",
    "        comments_by_hour[date2]+=comms\n",
    "        \n",
    "print(counts_by_hour)\n",
    "print(\" \")\n",
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average comments during each hour of the day\n",
    "Let's use the two dictionaries we've just created (`counts_by_hour` and `comments_by_hour`) to calculate the average number of comments for posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['02', 13.198237885462555],\n",
       " ['01', 9.367713004484305],\n",
       " ['22', 11.749128919860627],\n",
       " ['21', 11.056511056511056],\n",
       " ['19', 9.414285714285715],\n",
       " ['17', 13.73019801980198],\n",
       " ['15', 39.66809421841542],\n",
       " ['14', 13.153439153439153],\n",
       " ['13', 22.2239263803681],\n",
       " ['11', 11.143426294820717],\n",
       " ['10', 13.757990867579908],\n",
       " ['09', 8.392045454545455],\n",
       " ['07', 10.095541401273886],\n",
       " ['03', 10.160377358490566],\n",
       " ['16', 10.76144578313253],\n",
       " ['08', 12.43157894736842],\n",
       " ['00', 9.857142857142858],\n",
       " ['23', 8.322463768115941],\n",
       " ['20', 11.38265306122449],\n",
       " ['18', 10.789823008849558],\n",
       " ['12', 15.452554744525548],\n",
       " ['04', 12.688172043010752],\n",
       " ['06', 9.017045454545455],\n",
       " ['05', 11.139393939393939]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour=[]\n",
    "for row in counts_by_hour:\n",
    "    key1=row\n",
    "    comments=comments_by_hour[key1]\n",
    "    counts=counts_by_hour[row]\n",
    "    avg_by_hour.append([key1, comments/counts])\n",
    "\n",
    "# print for J's sanity\n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we now have the results we need, this format makes it hard to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 39.67 average comments per post.\n",
      "13:00: 22.22 average comments per post.\n",
      "12:00: 15.45 average comments per post.\n",
      "10:00: 13.76 average comments per post.\n",
      "17:00: 13.73 average comments per post.\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour=[]\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "\n",
    "sorted_swap=sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "for row in sorted_swap[0:5]:\n",
    "    template=\"{}: {:.2f} average comments per post.\"\n",
    "    hour1=dt.datetime.strptime(row[1], \"%H\")\n",
    "    hour2=dt.datetime.strftime(hour1,\"%H:%M\")\n",
    "    t=template.format(hour2, row[0])\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, which hours should you create a post during to have a higher chance of receiving comments? It looks like 10AM, noon, 1PM, 3PM, and 5PM are the best chances for your post to get the most engagement through comments (assuming you're posting an `AskHN` article!)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
